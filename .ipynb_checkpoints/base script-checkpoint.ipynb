{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wak76xYYUdXE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradientai in c:\\users\\rog\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: aenum>=3.1.11 in c:\\users\\rog\\anaconda3\\lib\\site-packages (from gradientai) (3.1.15)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.10.5 in c:\\users\\rog\\anaconda3\\lib\\site-packages (from gradientai) (1.10.13)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rog\\anaconda3\\lib\\site-packages (from gradientai) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\rog\\anaconda3\\lib\\site-packages (from gradientai) (1.26.16)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\rog\\anaconda3\\lib\\site-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rog\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradientai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U02ytLrPA2rG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GRADIENT_ACCESS_TOKEN'] = \"qBqla3HDQGwtcXLWuCdLRGcfzWqXAXKf\"\n",
    "os.environ['GRADIENT_WORKSPACE_ID'] = \"df0d36a2-8f4d-4f50-8e05-57eb2cd83c6f_workspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Scor9o08VVhQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model adapter with id ec6fea2d-7027-4113-aefc-bd691961a8d1_model_adapter\n",
      "Asking: ### Instruction: Who is Matthew Berman? \n",
      "\n",
      "### Response:\n",
      "Generated (before fine-tune):  Matthew Berman is a writer and producer, known for his work on the television series \"The Comeback\" and \"Curb Your Enthusiasm\".\n",
      "Fine-tuning the model, iteration 1\n",
      "Fine-tuning the model, iteration 2\n",
      "Fine-tuning the model, iteration 3\n",
      "Generated (after fine-tune):  Matthew Berman is a popular creator who talks about AI and its impact on society.\n"
     ]
    }
   ],
   "source": [
    "from gradientai import Gradient\n",
    "\n",
    "def main():\n",
    "  with Gradient() as gradient:\n",
    "      base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
    "\n",
    "      new_model_adapter = base_model.create_model_adapter(\n",
    "          name=\"test model 3\"\n",
    "      )\n",
    "      print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
    "      sample_query = \"### Instruction: Who is Matthew Berman? \\n\\n### Response:\"\n",
    "      print(f\"Asking: {sample_query}\")\n",
    "\n",
    "      # before fine-tuning\n",
    "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
    "      print(f\"Generated (before fine-tune): {completion}\")\n",
    "\n",
    "      samples = [\n",
    "        { \"inputs\": \"### Instruction: Who is Matthew Berman? \\n\\n### Response: Matthew Berman is a popular video creator who talks about AI\" },\n",
    "        { \"inputs\": \"### Instruction: Who is the person named Matthew Berman ? \\n\\n### Response: Matthew Berman is a YouTuber who talks about AI\" },\n",
    "        { \"inputs\": \"### Instruction: Can you tell me about Matthew Berman? \\n\\n### Response: Matthew Berman is a popular creator who specializes in AI content\" },\n",
    "      ]\n",
    "\n",
    "      # this is where fine-tuning happens\n",
    "      # num_epochs is the number of times you fine-tune the model\n",
    "      # more epochs tends to get better results, but you also run the risk of \"overfitting\"\n",
    "      # play around with this number to find what works best for you\n",
    "      num_epochs = 3\n",
    "      count = 0\n",
    "      while count < num_epochs:\n",
    "          print(f\"Fine-tuning the model, iteration {count + 1}\")\n",
    "          new_model_adapter.fine_tune(samples=samples)\n",
    "          count = count + 1\n",
    "\n",
    "      # after fine-tuning\n",
    "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
    "      print(f\"Generated (after fine-tune): {completion}\")\n",
    "\n",
    "      new_model_adapter.delete()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
