# GradientAI Fine-Tuning with GPT-3

GradientAI Fine-Tuning with GPT-3 is a demonstration of fine-tuning the GPT-3.5 Turbo model using GradientAI's platform. This repository provides a Python script that interacts with the GradientAI API to create a model adapter, fine-tune the GPT-3.5 Turbo model, and generate responses based on custom prompts.

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Getting Started](#getting-started)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Fine-Tuning](#fine-tuning)
- [Contributing](#contributing)
- [License](#license)

## Introduction

GradientAI Fine-Tuning with GPT-3 showcases the process of enhancing the GPT-3.5 Turbo model's capabilities through fine-tuning using the GradientAI platform. The provided Python script allows users to create a model adapter, fine-tune the model with custom samples, and observe the improved responses generated by the fine-tuned model.

## Features

- **Model Adapter Creation:** Interact with the GradientAI API to create a new model adapter.
- **Fine-Tuning:** Utilize custom samples to fine-tune the GPT-3.5 Turbo model.
- **Interactive CLI:** Engage with the command-line interface to input prompts and observe model-generated responses.

## Getting Started

These instructions will guide you through setting up the GradientAI Fine-Tuning with GPT-3 script on your local machine for interaction with the GradientAI platform.

### Prerequisites

- Python installed on your machine
- GradientAI package installed (use `pip install gradientai --upgrade`)

### Installation

1. Install the GradientAI package:

    ```bash
    pip install gradientai --upgrade
    ```

2. Clone the repository:

    ```bash
    git clone https://github.com/yourusername/gradientai-fine-tuning-gpt3.git
    ```

3. Change directory:

    ```bash
    cd gradientai-fine-tuning-gpt3
    ```

### Usage

1. Set up environment variables:

    ```bash
    export GRADIENT_ACCESS_TOKEN="your-gradient-access-token"
    export GRADIENT_WORKSPACE_ID="your-gradient-workspace-id"
    ```

2. Run the script:

    ```bash
    python fine_tune_gpt3.py
    ```

3. Follow the prompts to create a model adapter, fine-tune the model, and observe the generated responses.

## Fine-Tuning

Fine-tuning is a crucial step in enhancing the GPT-3.5 Turbo model's performance for specific use cases. Adjust the `num_epochs` variable in the script to control the number of fine-tuning iterations.

```python
# this is where fine-tuning happens
# num_epochs is the number of times you fine-tune the model
# more epochs tend to get better results, but you also run the risk of "overfitting"
# play around with this number to find what works best for you
num_epochs = 10
```
## Contributing
We welcome contributions from the community! If you find any issues or have suggestions, please open an issue or submit a pull request
